{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "DSwFQUGOD0iT",
        "TKlOXVFpJj7q"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yajima-yasutoshi/DataScience/blob/main/20250124/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 機械学習"
      ],
      "metadata": {
        "id": "DSwFQUGOD0iT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 20241224"
      ],
      "metadata": {
        "id": "g8YJ3oojiqNa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#本日の講義の目的\n",
        "\n",
        "機械学習による分類手法に関する説明を行う。\n",
        "ここでは、代表的な手法である\n",
        "**決定木**および**ランダムフォレスト**\n",
        "と呼ばれる2つの分類モデルの構築法を理解する。\n",
        "\n",
        "なお、決定木やランダムフォレストは2クラス（2値）の分類だけでなく、\n",
        "3クラス以上の一般のカテゴリ分類や、数値予測にも適応が可能である。\n",
        "\n",
        "利用するモジュールは以下のようになる。\n",
        "\n",
        "\n",
        "アルゴリズム(AI) | カテゴリ予測 | 数値予測\n",
        "-- | -- | --\n",
        "重回帰 | - | from sklearn.linear_model import LinearRegression\n",
        "ロジスティック回帰 | from sklearn.linear_model import LogisticRegression | -\n",
        "決定木  | from sklearn.tree import DecisionTreeClassifier | from sklearn.tree import DecisionTreeRegressor\n",
        "ランダムフォレスト | from sklearn.ensemble import RandomForestClassifier | from sklearn.ensemble import RandomForestRegressor\n"
      ],
      "metadata": {
        "id": "wUezl4MyB_v3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 【参考】\n",
        "\n",
        "*  決定木ライブラリー\n",
        "\n",
        " https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
        "\n",
        "\n",
        "* ランダムフォレストライブラリー\n",
        "\n",
        " https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n"
      ],
      "metadata": {
        "id": "Kag2HqlpNLtr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 準備\n"
      ],
      "metadata": {
        "id": "8zFBC9q961jw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 必要なライブラリーのインポート"
      ],
      "metadata": {
        "id": "ZcX_E1F-64Qu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# インストール\n",
        "!pip install japanize-matplotlib\n",
        "\n",
        "# 必要なライブラリをインポート\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib\n",
        "\n",
        "# 必要なライブラリのインポート\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "# 決定木に必要なライブラリー\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "\n",
        "# ランダムフォレストに必要なライブラリー\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# その他必要なライブラリー\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "g9TNYrU66eru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cancerデータを使った例"
      ],
      "metadata": {
        "id": "gRs3b9V4wBaU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## データ\n",
        "\n",
        "sklean ライブラリーに格納されているサンプルデータ（cancer data）を使い\n",
        "**決定木**の説明を行う。\n",
        "\n",
        "まず、データを読み込む。"
      ],
      "metadata": {
        "id": "THzc4_hPdU3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "df = pd.DataFrame(cancer.data, columns = cancer.feature_names)\n",
        "df['diagnosis'] = cancer.target\n",
        "df.info()"
      ],
      "metadata": {
        "id": "bPDzMK4uN0IV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "これは、30項目の細胞に関連したデータ（サイズ、形状、など）と\n",
        "そこから判断された癌の診断結果（'diagnosis'）のデータである。\n",
        "\n",
        "全ての項目は数値型で、\n",
        "特に診断結果（'diagnosis'）は\n",
        "\n",
        "* 悪性の場合には 0\n",
        "* 良性の場合には 1\n",
        "\n",
        "が入力されており、\n",
        "このような項目を**2値**の項目と呼ぶ。\n",
        "\n",
        "このデータを学習させて、\n",
        "細胞に関する30項目を説明変数として\n",
        "**癌の診断（良性か悪性かの分類）を行うAIを構築**する。"
      ],
      "metadata": {
        "id": "LdH53ARgIepY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 基礎集計"
      ],
      "metadata": {
        "id": "vIWgvtP6yxIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "ardSEPbiDn-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "diagnosis は数値型の項目ではあるが、値は 0 と 1 の2値となっていることが確かめられる。\n"
      ],
      "metadata": {
        "id": "ZUq7hgo472nI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['diagnosis'].value_counts()"
      ],
      "metadata": {
        "id": "FW_ER1W5-b3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ヒストグラムを作成して、各項目の分布を確認する。\n",
        "hue を使いdiagnosisで色分けしてみる"
      ],
      "metadata": {
        "id": "F-qS51aHhHhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(data=df, x='mean radius', hue='diagnosis', kde=True)"
      ],
      "metadata": {
        "id": "VNU4Aza-Dcie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "このグラフからは、mean radius がおよそ18をこえるとほぼ全てが悪性、\n",
        "逆に10を下回るとほぼ全てが良性になっていることが分かる。\n",
        "\n",
        "一方で、10から18の間では、良性も悪性もあり、この項目だけでは\n",
        "悪性か良性かを判断できないことが分かる。"
      ],
      "metadata": {
        "id": "bG_bnzU9yk52"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 決定木\n",
        "30項目の数値データと癌の診断結果（diagnosis）から、\n",
        "悪性か良性かを分類するAIを構築する。\n",
        "\n",
        "悪性か良性かといった分類問題に対する代表的な機械学習の手法として、\n",
        "**「決定木」**の使い方を説明する。"
      ],
      "metadata": {
        "id": "kflta2TyOaRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 変数\n",
        "\n",
        "今までの予測と同様に、説明変数と目的変数を定める。\n",
        "\n",
        "* **説明変数：** 予測する元になる項目。上のデータでは30項目の数値型データがある。\n",
        "* **目的変数：** 予測の対象となる項目。上のデータでは diagnosis である。\n",
        "\n",
        "なお、決定木の場合には、**説明変数の標準化は不要である**。\n"
      ],
      "metadata": {
        "id": "XECHEz4EhU7n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "説明変数と目的変数をそれぞれ別の変数（X と y）にセットする。"
      ],
      "metadata": {
        "id": "Spn955w6t_Bl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 項目'diagnosis'は変数dfの最後にある項目なので、それを除くと説明変数のみとなる\n",
        "X = df.iloc[:,:-1]\n",
        "y = df[['diagnosis']]"
      ],
      "metadata": {
        "id": "pyHf_wHjOknH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 必要なライブラリのインポート\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# データを学習用データと検証用データに分割\n",
        "# test_size は、0.2 から 0.3 程度が良いとされる\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "iu6fawtBVpj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##決定木モデルを学習する"
      ],
      "metadata": {
        "id": "4I3xbCtTxWvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 決定木に必要なライブラリー\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 決定木のインスタンスを作成\n",
        "model = DecisionTreeClassifier(max_depth=2, random_state=0)\n",
        "\n",
        "# 学習\n",
        "model.fit(X_train, y_train.values.ravel())"
      ],
      "metadata": {
        "id": "rhyQN6dmeEWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "決定木の内部では、以下の図に示すような\n",
        "予測がモデルが構築される。"
      ],
      "metadata": {
        "id": "4J3fhou1O_ff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 決定木を可視化する\n",
        "plt.figure(figsize=(16,6))\n",
        "plot_tree(model, filled=True, feature_names=cancer.feature_names, class_names=['0（悪性）','1（良性）'], fontsize=14)\n",
        "plt.title(\"Decision Tree of Cancer Dataset\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NMmARcJNDi9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "決定木モデルでは、説明変数の値の大小で\n",
        "上の図のように枝分かれしながら予測が行われる。\n",
        "上の図の場合は\n",
        "max_depth=2 と指定したので、\n",
        "2回枝分かれをするモデルになっている。\n",
        "データが不等式の条件を満たせば左、満たさない場合は右方向に枝を下方向に\n",
        "たどりながら、最後に到達した箱の class が予測結果である。\n",
        "\n",
        "上の場合では、枝分かれに用いられた項目は\n",
        "worst concave points\n",
        "と\n",
        "worst area\n",
        "の2つであった。\n",
        "この二つが目的変数（この例では良性か悪性か）の判断に有効である、\n",
        "との結果になったことを意味している。\n",
        "\n",
        "例えば、ある細胞のデータが、\n",
        "\n",
        "* worst concave points = 0.2\n",
        "* worst area = 700\n",
        "\n",
        "であった場合、予測結果は class=1 (良性)と判定される。\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0HAiK8PQP1IP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(data=df, x='worst concave points', hue='diagnosis', kde=True)"
      ],
      "metadata": {
        "id": "gZpKmrf2GIVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(data=df, x='worst area', hue='diagnosis', kde=True)"
      ],
      "metadata": {
        "id": "abUwm9xtbUjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.jointplot(x='worst concave points', y='worst area', data=df, hue='diagnosis')"
      ],
      "metadata": {
        "id": "VS4hiFAOb4q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 評価用のデータを使い予測精度を確認する"
      ],
      "metadata": {
        "id": "XC28vVTzraqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# テストデータで予測\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "# 精度を計算\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "wGnlA5gerXf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "混同行列（confusion matrix）でも確認する。"
      ],
      "metadata": {
        "id": "eHhTt36wYUki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_val, y_pred)"
      ],
      "metadata": {
        "id": "rSOYxiTfX4ZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Titanic データを使った例（決定木）"
      ],
      "metadata": {
        "id": "TKlOXVFpJj7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データを読み込む\n",
        "data = sns.load_dataset(\"titanic\") #タイタニックのデータ\n",
        "data.info()\n",
        "data.head(5)"
      ],
      "metadata": {
        "id": "j_M6pfGUdT3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##データの説明\n",
        "\n",
        "列名 | 意味\n",
        "---  | ---\n",
        "survived\t| 生存フラグ（0=死亡、1=生存）\n",
        "pclass\t| チケットクラス（1stクラス、2ndクラス、3rdクラス）\n",
        "sex\t| 性別（male=男性、female＝女性）\n",
        "sge\t| 年齢\n",
        "sibsp\t| タイタニックに同乗している兄弟/配偶者の数\n",
        "parch\t| タイタニックに同乗している親/子供の数\n",
        "fare\t| 料金\n",
        "embarked\t| 出港地（タイタニックへ乗った港）(C=Cherbourg、Q=Queenstown、S=Southampton)\n",
        "class | 乗船クラス\n",
        "who |男性 or 女性\n",
        "adult_male | 成人男性であるかどうか\n",
        "deck | 乗船していたデッキ\n",
        "embark_town | 出港地\n",
        "alive | 生存したかどうか\n",
        "alone | 一人であったかどうか"
      ],
      "metadata": {
        "id": "t7UJupBadfY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 欠損値を埋める\n",
        "data['age'].fillna(data['age'].mean(), inplace=True)\n",
        "data['embarked'].fillna(data['embarked'].mode()[0], inplace=True)\n",
        "data['embark_town'].fillna(data['embark_town'].mode()[0], inplace=True)\n",
        "# 結果を確認\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "_jzkQkrvd8kV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# カテゴリ変数をOne Hot Encoding\n",
        "data_encoded = pd.get_dummies(data[['sex', 'embarked', 'class', 'who', 'adult_male', 'alone']], drop_first=True)\n",
        "\n",
        "# 説明変数と目的変数を設定\n",
        "X = pd.concat([data[['age', 'fare', 'sibsp', 'parch']], data_encoded], axis=1)\n",
        "y = data['survived']"
      ],
      "metadata": {
        "id": "p9WKguxbTHe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ハイパーパラメータの max_depth を 2 として決定木を作る。"
      ],
      "metadata": {
        "id": "KkpE3METg9Va"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データを訓練セットとテストセットに分割\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 最適なモデルを作成\n",
        "model = DecisionTreeClassifier(max_depth=2, random_state=0)\n",
        "model.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# 検証用データで予測\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "# 精度を計算\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "um78RN1OSiSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 決定木を可視化する\n",
        "plt.figure(figsize=(10,5))\n",
        "plot_tree(model, filled=True,  fontsize=14, feature_names=X.columns[:-1], class_names=['0(死亡)','1(生存)'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KqOSpXd9b3pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "一番上の who_man は、カテゴリ項目 who を One hot encoding した項目で、\n",
        "who の値が man であれば 1 、そうでないなら 0 になっている。\n",
        "\n",
        "who_man <= 0.5 という不等式なので、0 （すなわち man でない）ならば左側に、\n",
        "1 ならば右側に枝分かれする。\n",
        "\n",
        "例えば、\n",
        "* who = woman\n",
        "* class = Third\n",
        "の場合は「死亡」と予測されることになる。\n"
      ],
      "metadata": {
        "id": "ISLznoFbu63g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ハイパーパラメータチューニング\n",
        "\n",
        "決定木のハイパーパラメータは max_depth である。\n",
        "max_depth を 2から20の範囲で\n",
        "以下のようにグリッドサーチを行う。\n"
      ],
      "metadata": {
        "id": "MJCqr3iMhLj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# ハイパーパラメータの候補\n",
        "param_grid = {\n",
        "    'max_depth': [2, 3, 4, 5, 10, 20]\n",
        "    }\n",
        "\n",
        "# グリッドサーチで最適なハイパーパラメータを探す\n",
        "grid_search = GridSearchCV( DecisionTreeClassifier(), param_grid=param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train.values.ravel())"
      ],
      "metadata": {
        "id": "q1GBsffU5UGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "最適なパラメータは grid_search.best_estimator_ にセットされる。"
      ],
      "metadata": {
        "id": "bbuhqJ99iSPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.best_params_"
      ],
      "metadata": {
        "id": "6R1Lgci9aK8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 最適なモデルを作成\n",
        "model = grid_search.best_estimator_\n",
        "model.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# テストデータで予測\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "# 精度を計算\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "XKZ9OmOGadY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 決定木を可視化する\n",
        "plt.figure(figsize=(15,7))\n",
        "plot_tree(model, filled=True,  fontsize=13, feature_names=X.columns[:-1], class_names=['0(死亡)','1(生存)'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fo8ix57GjX22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n"
      ],
      "metadata": {
        "id": "sKSxEjEQyAue"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ランダムフォレスト\n",
        "分類問題に対する代表的な機械学習の手法として、\n",
        "**「ランダムフォレスト」**の使い方を説明する。\n",
        "\n",
        "ランダムフォレストは、決定木を複雑に組み合わせた構造を持ち、\n",
        "高い予測精度となるように工夫されてる。\n",
        "決定木と同様に、カテゴリ型の予測だけでなく\n",
        "数値型の予測も行える高精度な万能な予測手法である。\n",
        "ビジネスでも多く用いられている手法である。\n",
        "\n",
        "ただし、決定木のように予測の内部構造を可視化することができない。\n",
        "また、ランダムフォレストを利用するためには、\n",
        "複数のハイパーパラメータの調整が必要で、\n",
        "他の機械学習法と比べて多くの計算時間を必要とする。\n"
      ],
      "metadata": {
        "id": "-LjhwtSgB3va"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ランダムフォレストモデルを学習する"
      ],
      "metadata": {
        "id": "N0DJ5GwBB3vk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "学習を行う関数は、今までと同様で fit であり、\n",
        "以下のように用いる\n",
        "\n",
        "```\n",
        "model = RandomForestClassifier()\n",
        "model.fit(説明変数, 目的変数)\n",
        "```\n",
        "\n",
        "である。\n",
        "\n",
        "Titanic Data を使い学習を行い検証用のデータで精度を評価する。"
      ],
      "metadata": {
        "id": "ryOuMaiEB3vk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ランダムフォレストに必要なライブラリー\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# ランダムフォレストのインスタンスを作成\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "# 学習\n",
        "model.fit(X_train, y_train.values.ravel())"
      ],
      "metadata": {
        "id": "l1bfdIMxB3vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 評価データで予測\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "# 精度を計算\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "accuracy"
      ],
      "metadata": {
        "id": "UKXQlC4kB3vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ランダムフォレストでは、説明変数の重要度を表示できる。\n",
        "値が大きいほど、予測精度に寄与する度合いが大きいことを意味している。\n",
        "重要度の小さな変数を用いなくてもほとんど精度に影響がない、\n",
        "逆に重要度の大きな変数を用いない場合は精度が悪化する。\n",
        "\n",
        "重要度の値は全て正となり、回帰係数とは異なる意味合いの物である。"
      ],
      "metadata": {
        "id": "SoZUfZShB3vm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.feature_importances_"
      ],
      "metadata": {
        "id": "kXoL1pMwB3vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 特徴量の重要度を可視化\n",
        "sns.barplot(x=model.feature_importances_, y=X.columns)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O8phEcnwB3vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ハイパーパラメータチューニング\n",
        "\n",
        "ランダムフォレストを利用するためには、\n",
        "いくつかのハイパーパラメータを適切に設定する必要がある。\n",
        "上の例ではデフォルト値が用いられているが、\n",
        "変更することでより精度を向上させることが可能である。\n",
        "\n",
        "調整することで精度の向上が期待できるパラメーターには以下のものがある。\n",
        "\n",
        "*  n_estimators（木の数）: 10 ～ 1000 程度\n",
        "*  max_depth（木の深さ） : 3 ～ 100 程度\n",
        "*  min_samples_split（分割の最小のサンプル数）: 2 ～ 100 程度"
      ],
      "metadata": {
        "id": "LnnPimVGB3vn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ランダムフォレストに必要なライブラリー\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# ハイパーパラメータの候補\n",
        "param_grid = {\n",
        "    'n_estimators': [20, 50, 100, 200],\n",
        "    'max_depth': [3, 10, 20, 30, 50],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# グリッドサーチで最適なハイパーパラメータを探す\n",
        "grid_search = GridSearchCV( RandomForestClassifier(), param_grid=param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# 最適なハイパーパラメータを出力\n",
        "print(\"Best Parameters: \", grid_search.best_params_)\n",
        "\n",
        "# 最適なモデルを作成\n",
        "model = grid_search.best_estimator_\n",
        "\n",
        "# 学習\n",
        "model.fit(X_train, y_train.values.ravel())\n"
      ],
      "metadata": {
        "id": "d7LavvorB3vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 精度の評価\n",
        "\n",
        "評価用のデータセットを用いて精度の評価を行う。\n"
      ],
      "metadata": {
        "id": "Qgee4DKUB3vo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 評価データで予測\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "# 精度を計算\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "accuracy"
      ],
      "metadata": {
        "id": "m3mIlrVJB3vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "検証用データの場合で、混同行列を作成する。"
      ],
      "metadata": {
        "id": "9QnbWB2OB3vq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_val, y_pred)"
      ],
      "metadata": {
        "id": "_-4BQGZAB3vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n"
      ],
      "metadata": {
        "id": "D2u9eGlQai1Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Iris データを使った例"
      ],
      "metadata": {
        "id": "WwTwWamkvRko"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## データ\n",
        "\n",
        "アイリスデータセットには、\n",
        "3種類のアイリス花（セトサ、バーシクル、バージニカ）各50レコード\n",
        "の計150レコードが記録されている。\n",
        "\n",
        "各項目は以下の通り\n",
        "\n",
        "項目名 | 型 | 説明\n",
        "--  | -- | --\n",
        "Petal Length | 数値 | 花びらの長さ\n",
        "Petal Width  | 数値 | 花びらの幅\n",
        "Sepal Length | 数値 | がく片の長さ\n",
        "Sepal Width | 数値 | がく片の幅\n",
        "species     | カテゴリ | 花の種類（セトサ、バーシクル、バージニカ）\n",
        "\n",
        "花びらの長さなど4つの項目から花の種類を予測するAIを作る。"
      ],
      "metadata": {
        "id": "OvJfoFNbyGkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# seabornからデータをロードする\n",
        "df = sns.load_dataset('iris')\n",
        "df.info()\n",
        "df.head()"
      ],
      "metadata": {
        "id": "lvSKrnQmy7vN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 決定木を使った花の種類の予測"
      ],
      "metadata": {
        "id": "GevBpAyvkndZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 特徴量とラベルを分ける\n",
        "X = df.drop('species', axis=1)\n",
        "y = df['species']\n",
        "\n",
        "# データを学習セットとテストセットに分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 決定木のインスタンスを作成\n",
        "model = DecisionTreeClassifier(max_depth=2)\n",
        "\n",
        "# 学習\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 予測\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 精度を計算\n",
        "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "qZgN1ZvFndXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 決定木を可視化する\n",
        "\n",
        "決定木モデルの枝分かれの様子を可視化する"
      ],
      "metadata": {
        "id": "mbjdeISZq9Ha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 決定木を可視化する\n",
        "plt.figure(figsize=(10,5))\n",
        "plot_tree(model, filled=True,  fontsize=12, feature_names=df.columns[:-1], class_names=df['species'].unique() )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Fsl6IHmfq-vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 特徴量とラベルを分ける\n",
        "X = df.drop('species', axis=1)\n",
        "y = df['species']\n",
        "\n",
        "# データを学習セットとテストセットに分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 決定木のインスタンスを作成\n",
        "model = DecisionTreeClassifier(max_depth=2)\n",
        "\n",
        "# 学習\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 予測\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 精度を計算\n",
        "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
        "\n",
        "\n",
        "# ハイパーパラメータの候補\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# グリッドサーチで最適なハイパーパラメータを探す\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 最適なハイパーパラメータを出力\n",
        "print(\"Best Parameters: \", grid_search.best_params_)\n",
        "\n",
        "# 最適なモデルを取得\n",
        "best_rf = grid_search.best_estimator_\n",
        "\n",
        "# 学習\n",
        "best_rf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = best_rf.predict(X_test)\n",
        "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# 特徴量の重要度を可視化\n",
        "feature_importances = best_rf.feature_importances_\n",
        "sns.barplot(x=feature_importances, y=X.columns)\n",
        "plt.title('Feature Importances')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sA4WKDgEvg2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "bCh8c-6jReuv"
      }
    }
  ]
}